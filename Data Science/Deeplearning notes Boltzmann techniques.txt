To practice on datasets given in the websites below:
1. website: www.grouplens.org/datasets/movielens/
for new research
new education and research

import, train and test the 
binary rating

what is spyder(python 3.6) application contains is it a file explorer?
file explorer and variable explorer
file explorer -> something.. -> vol2 -> deeplearning -> part5 Boltzmann machine -> set console work directory -> ml-1million, ml-100K, AltRBM-proof.pdf

Boltzmann machine contains (2.0 graphical models/2.1 undirected graphs and Markov random fields/2.2 unsupervised learning with mathematical KL-divergence something... and optimization by gradient ascent), (3.0 Markov chains and morkov chain monte carlo techniques/ 3.2 gibbs sampling), (4.0 Restricted Boltzmann machines/ 4.1 Gradient of the log-likelihood/ 5.1 contrastive divergence)

<p>we will be working on the same dataset as in Part 6 - AutoEncoders so the Data Preprocessing phase is the same for Parts 5 and 6. Therefore, if you already completed Part 6, feel free to skip the five following tutorials and jump directly to the Lecture: Building a Boltzmann Machine - Step 6.</p>

STEP 1:
------
CODE:
-----
import numpy as np (for arrays)
import pandas as pd (for datasets, trainsets and testsets)
import torch
import torch.nn as nn (for nueral networks)
import torch.nn.parallel (for parallel computations)
import torch.optim as optim (optimizer)
import torch.utils.data ()
from torch.utils.autograd import Variable (statistic)

#STEP1 Importing the dataset
movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')

users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')

ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')

#STEP2 Preparing the training set and the test set
training_set = pd.read_csv('ml-100k/ul.base', delimiter = '\t')
training_set = np.array(training_set, dtype = 'int')
test_set = pd.read_csv('ml-100k/ul.test', delimiter = '\t')
test_set = np.array(test_set, dtype = 'int')

#STEP3 Getting the number of users and movies
nb_users = int(max(training_set[:,0]), max(test_set[:,0])))
nb_movies = int(max(training_set[:,1]), max(test_set[:,1])))

#STEP4 Converting the data into an array with users in lines and movies in columns
def convert(data):
    new_data = []
    for id_users in range(1, nb_users + 1):
        id_movies = data[:,1][data[:,0] == id_users]
	id_ratings = data[:,2][data[:,0] == id_users]
	ratings = np.zeros(nb_movies)
	ratings[id_movies - 1] = id_ratings
	new_data.append(list(ratings))
     return new_data
training_set = convert(training_set)
test_set = convert(test_set)

#STEP5 Converting the data into Torch tensors
training_set = torch.FloatTensor(training_set)
test_set = torch.FloatTensor(test_set)

#STEP6 Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)
training_set[training_set == 0] = -1
training_set[training_set == 1] = 0
training_set[training_set == 2] = 0
training_set[training_set >= 3] = 1
test_set[test_set == 0] = -1
test_set[test_set == 1] = 0
test_set[test_set == 2] = 0
test_set[test_set >= 3] = 1

#STEP 7,8 Creating the architecture of the Neural Network
class RBM():
     def __init__(self, nv, nh):
         self.w = torch.randn(nh, nv)
         self.a = torch.randn(l, nv)
         self.b = torch.randn(r, nv)
    def sample_h(self, x):
	wx = torch.mm(x, self.W.t())
	activation = wx + self.a.expand_as(wx)
	p_h_given_v = torch.sigmoid(activation)
	return p_h_given_v, torch.bernoulli(p_h_given_v)
    def sample_v(self, y):
	wy = torch.mm(y, self.w)
	activation = wy + self.b.expand_as(wy)
	p_v_given_h = torch.sigmoid(activation)
	return p_v_given_h, torch.bernoulli(p_v_given_h)
    def train(self, v0, vk, ph0, phk):
	self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)
	self.b += torch.sum((v0 - vk), 0)
	self.a += torch.sum((ph0 - phk), 0)
nv = len(training_set[0])
nh = 100
batch_size = 100
rbm = RBM(nv, nh)

# Training the RBM
nb_epoch = 10
for epoch in range(1, nb_epoch + 1):
  train_loss = 0
  s = 0,
  for id_user in range(0, nb_users - batch_size, batch_size):
	vk = training_set[id_user:id_user+batch_size]
	v0 = training_set[id_user:id_user+batch_size]
	ph0, _ = rbm.sample_h(v0)
	for k in range(10):
		_, hk = rbm.sample_h(vk)
		_, vk = rbm.sample_v(hk)
		vk[v0<0] = v0[v0<0]
	phk, _ = rbm.sample_h(vk)
	rbm.train(v0, vk, ph0, phk)
	train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))
        s += 1
   print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))

# Testing the RBM
test_loss = 0
s = 0,
for id_user in range(nb_users):
	v = training_set[id_user:id_user+1]
	vt = training_set[id_user:id_user+1]
	for len(vt[vt>=0]) > 0:
		_, h = rbm.sample_h(v)
		_, v = rbm.sample_v(h)
		vk[v0<0] = v0[v0<0]
	phk, _ = rbm.sample_h(vk)
	rbm.train(v0, vk, ph0, phk)
	train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))
        s += 1
   print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))


CHECK THE VIDEO 18

================================================================================

















































































